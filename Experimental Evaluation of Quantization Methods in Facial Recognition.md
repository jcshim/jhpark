제공해주신 논문 **"Experimental Evaluation of Quantization Methods in Facial Recognition"**의 주요 내용을 요약해 드립니다. 이 논문은 안면 인식 모델에 양자화(Quantization) 기술을 적용했을 때 성능과 저장 공간에 미치는 영향을 실험적으로 평가했습니다.

### 1. 연구 개요 및 목적
*   **배경:** 안면 인식 AI 도구의 사용이 증가함에 따라 대용량 데이터 저장 및 높은 정확도 유지라는 과제가 발생했습니다. 이를 해결하기 위해 모델 최적화 전략으로 양자화를 평가했습니다.
*   **목표:** 두 가지 주요 안면 인식 모델인 **Facenet**(Inception-ResNet 기반)과 **Transface**(Vision Transformer 기반)를 대상으로, 정밀도 포맷(FP32 vs. INT8)과 추론 백엔드(Torch vs. ONNX)에 따른 성능 변화를 비교했습니다.

### 2. 실험 방법론
*   **데이터셋:** 실험에는 LFW, VGGFace2, CelebA 등 세 가지 데이터셋이 사용되었으며, 모든 이미지는 얼굴 검출 및 정렬 과정을 거쳤습니다.
*   **모델 변환 및 양자화:**
    *   기존 Torch 모델을 ONNX 포맷으로 변환하여 플랫폼 간 가변성을 테스트했습니다.
    *   **ONNX 정적 양자화(Static Quantization):** 가중치와 활성화 함수를 모두 INT8로 변환했습니다.
    *   **Torch 동적 양자화(Dynamic Quantization):** 추론 시점에 선형 및 LSTM 레이어를 동적으로 양자화했습니다.
*   **평가 지표:** 코사인 거리(Cosine Distance)를 사용하여 유사도를 측정하고, Rank-1 정확도를 검증했습니다.

### 3. 주요 연구 결과
이 연구는 크게 세 가지 연구 질문(RQ)에 대한 답을 제시합니다.

**RQ1: 양자화 적용 시 정확도 감소율은?**
*   **Facenet:** 양자화에 매우 강인한 모습을 보였습니다. 정확도 변화가 0.2% 미만으로 무시할 수 있는 수준이었습니다.
*   **Transface:** 양자화 시 눈에 띄는 성능 저하가 발생했습니다. 특히 ONNX 정적 양자화 적용 시 최대 4%까지 정확도가 떨어졌습니다.

**RQ2: Torch 동적 양자화와 ONNX 정적 양자화의 차이는?**
*   **Facenet:** 두 양자화 방식 간에 유의미한 차이가 없었으며, ONNX로 변환 시 오히려 성능이 약간 향상되는 경우도 있었습니다.
*   **Transface:** Torch의 동적 양자화가 ONNX 정적 양자화보다 성능 저하가 덜했습니다. ONNX 정적 양자화에서는 정확도가 크게 떨어져 Transformer 기반 모델이 가중치와 활성화 함수의 동시 양자화에 취약함을 보여주었습니다.

**RQ3: 모델 아키텍처별 양자화 민감도는?**
*   기본 성능(FP32)은 Transface가 Facenet보다 우수하지만, 양자화 민감도는 Transface가 훨씬 높았습니다. Facenet과 같은 합성곱(Convolutional) 기반의 성숙한 모델이 양자화에 더 안정적입니다.

### 4. 저장 공간 절감 효과
*   임베딩 벡터를 32비트 부동소수점(FP32)에서 8비트 정수(INT8)로 변환하여 저장할 경우, 정확도 손실 없이 **디스크 사용량을 약 80% 절감**할 수 있었습니다.
*   예를 들어, CelebA 데이터셋의 경우 2.07GB에서 401MB로 용량이 감소했습니다.

### 5. 결론
*   최고의 정확도가 최우선이고 자원이 충분하다면 **Transface(Vision Transformer)** 모델이 유리합니다.
*   하지만 리소스가 제한적이거나 공격적인 양자화가 필요한 환경에서는 **Facenet**이 더 신뢰할 수 있고 일관된 성능을 보입니다.
*   임베딩 데이터 타입을 변경하는 것만으로도 성능 저하 없이 저장 공간을 획기적으로 줄일 수 있어 클라우드나 엣지 디바이스 환경에서 유용합니다.
